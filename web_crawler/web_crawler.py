import requests, re


to_crawl = ['https://wikileaks.org']
crawled = set()

header = {'user-agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.92 Safari/537.36'}

while True:
    url = to_crawl[0]
    try:
        request = requests.get(url, headers=header)
    except:
        to_crawl.remove(url)
        crawled.add(url)
        continue
    html = request.text
    """
    padrao = re.findall(r'href=[\'"](https?://[\w:/\.\'"_]+)', html)
        
    for l in padrao:
        print(l)
    """
    ### OU

    to_crawl.remove(url)
    crawled.add(url)

    padrao = re.findall(r'<a href="?\'?(https?:\/\/[^"\']*)', html)
    print("O Chefe, achamos isso: ", url)

    for l in padrao:
        if l not in crawled and l not in to_crawl:
            to_crawl.append(l)
